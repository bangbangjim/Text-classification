{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In here I have tried to classify the categories of each text in the fetch_20newsgroups dataset belongs to. Different vector representation of the text, ML techniques (supervised and unsupervised) and hyperparameters (using GridSearchCV) were tested. In short, when text is represented by the averaged GloVE vectors of the noun chunks in the text, the resulting vector representation would gives high accuracy performance in all the ML models tested (SVM, K-nearest neighbours and K-means clustering). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "The dataset that is being used is the fetch_20newsgroups that can be imported from the sk-learn library. It contains around 18000 pieces of labelled text which are categorised into 20 classes. The headers, footers and quotes usually gives out a lot of hint regarding the categories the text belongs to and therefore resulting is a really high accuracy rate. It would be more ideal however, if we could develop a model that can accurately predict the classes based just on the text body, and therefore the headers, footers and quotes are removed from each training example.\n",
    "\n",
    "\n",
    "First, the text is transformed into a Term Frequencyâ€“Inverse Document Frequency (tf-idf) vectors and Multinomial Naive Bayes and SVM (SGDClassifier) were tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = fetch_20newsgroups(subset = \"train\", shuffle = True, remove = (\"headers\", \"footers\", \"quotes\"))\n",
    "test_set = fetch_20newsgroups(subset = \"test\", shuffle = True, remove = (\"headers\", \"footers\", \"quotes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB: 0.6062134891131173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\chatbot\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM (SGD): 0.6931757833244823\n"
     ]
    }
   ],
   "source": [
    "tfidf  = TfidfVectorizer()\n",
    "Mn_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                      ('clf', MultinomialNB())])\n",
    "Mn_clf = Mn_clf.fit(train_set.data, train_set.target)\n",
    "print (\"MultinomialNB: \" + str(Mn_clf.score(test_set.data, test_set.target)))\n",
    "\n",
    "#Gaussian commented out because it's too slow (need to transform to dense vector)\n",
    "# G_clf = Pipeline([('tfidf', TfidfVectorizer()), \n",
    "#                   ('to_dense', FunctionTransformer(lambda x: x.todense(), accept_sparse = True)),\n",
    "#                       ('clf', GaussianNB())])\n",
    "# G_clf = G_clf.fit(train_set.data, train_set.target)\n",
    "# print (\"GausianNB: \" + str(G_clf.score(test_set.data, test_set.target)))\n",
    "\n",
    "SVM_clf = Pipeline([(\"tfidf\", TfidfVectorizer()),\n",
    "                    (\"SGDClassifier\", SGDClassifier())])\n",
    "SVM_clf.fit(train_set.data, train_set.target)\n",
    "\n",
    "print (\"SVM (SGD): \" + str(SVM_clf.score(test_set.data, test_set.target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it can be seen that SVM perform a lot better than a MultinomialNB does and therefore I decided to do tuning on the hyperparameters with GridSearchCV. But before doing it, notice that by default the train and test set is split in 60:40. This is not really neccessary especially when I am doing 5-fold CV during the grid search anyway. Therefore I splitted the dataset into training and testing set with approximately a 80:20 ratio instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6003395946089356\n",
      "15076.800000000001\n",
      "15076 3770\n"
     ]
    }
   ],
   "source": [
    "print (len(train_set.data)/ (len(train_set.data) + len(test_set.data)))\n",
    "print ((len(train_set.data) + len(test_set.data)) * 0.8)\n",
    "whole_set = fetch_20newsgroups(subset = \"all\", shuffle = True, remove = (\"headers\", \"footers\", \"quotes\"))\n",
    "X_train, X_test, y_train, y_test = train_test_split(whole_set.data, whole_set.target, test_size = 0.2, random_state = 10)\n",
    "print (len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several parameters were tested as indicated in the parameters dictionary. Also stop words were removed because more often than not they reduces performance of text classification. max_df is the maximum document frequency that the word can have in order to be included in the vocabulary. This eliminates terms that appears too frequent (just like stop-words) and therefore might not bear much use for the classificaiton problem. In contrast, min_df eliminates terms that appears too few times (e.g. misspelled words). \n",
    "\n",
    "During Grid Search, 5-fold cross-validation is performed and refit is set to True so that in the end, the best estimator is trained again but this time with the entire training data (no validation set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_clf = Pipeline([(\"tfidf\", TfidfVectorizer()),\n",
    "                    (\"SGDClassifier\", SGDClassifier())])\n",
    "\n",
    "parameters = {\"tfidf__ngram_range\": [(1,1), (1,2), (1,3)],\n",
    "              \"tfidf__max_df\": [0.3,0.5,1.0],\n",
    "              \"tfidf__max_features\": [None, 25000],\n",
    "              \"tfidf__min_df\": [5,10],\n",
    "             \"tfidf__stop_words\": [\"english\",],\n",
    "              \"SGDClassifier__alpha\": [0.0001, 0.0002]}\n",
    "\n",
    "\n",
    "SVM_clf_gs = GridSearchCV(SVM_clf, parameters, n_jobs = -1, refit = True, cv = 5)\n",
    "SVM_clf_gs = SVM_clf_gs.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best CV score: 0.7468\n",
      "best parameters: {'SGDClassifier__alpha': 0.0001, 'tfidf__max_df': 0.5, 'tfidf__max_features': None, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': 'english'}\n",
      "test score: 0.7524700988039521\n"
     ]
    }
   ],
   "source": [
    "print (\"best CV score: \" + str(SVM_clf_gs.best_score_))\n",
    "print (\"best parameters: \" + str(SVM_clf_gs.best_params_))\n",
    "print(\"test score: \" + str(SVM_clf_gs.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the test score is slightly that the CV score, this could be a result of the fact that the CV score is an averaged out score, where there could be a high variance in each of the individual CV score. Also, the model is refitted to the entire dataset, which can result in a better performance.\n",
    "\n",
    "Next I decided to tried Unsupervised learning (K-mean clustering) to solve the classification problem. For simiplicity sake, I have started this task with only 2 catagories of data so it is easier to measure the accuracy of the K-mean clustering model. I have also tested the performance of SVM as well as K-nearest neighbors because I wanted to see how much changing the features can affect the performances.\n",
    "\n",
    "I have also noticed that there are training example in the dataset that are just empty string, so because of that, I have filtered out all the data that is an empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import homogeneity_completeness_v_measure\n",
    "\n",
    "def scoring(clf, train_x, test_x, train_y, test_y):\n",
    "    name = clf[0]\n",
    "    clf = clf[1]\n",
    "    if name != \"KMEANS\":\n",
    "        clf.fit(train_x, train_y)\n",
    "        return (name + \" accuracy: \" + str(clf.score(test_x, test_y)) )\n",
    "    else:\n",
    "        clf = clf.fit(train_x)\n",
    "#        print (max(np.mean(KM_clf.predict(train_x) == train_y), 1-np.mean(KM_clf.predict(train_x) == train_y)))\n",
    "        acc = str(max(np.mean(clf.predict(test_x) == test_y), 1- np.mean(clf.predict(test_x) == test_y)))\n",
    "        hcv = homogeneity_completeness_v_measure(test_y, clf.predict(test_x))\n",
    "        return (\"{0} accuracy: {1}, homo: {2}, comp: {3}, vm: {4}\".format(name, acc, *hcv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1618\n",
      "1538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\chatbot\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy: 0.9253246753246753\n",
      "KMEANS accuracy: 0.762987012987013, homo: 0.23602164328037573, comp: 0.35654418939491794, vm: 0.28402631688408747\n",
      "K-nearest accuracy: 0.6428571428571429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "cats = [\"rec.autos\", 'talk.religion.misc']\n",
    "data_set = fetch_20newsgroups(subset = \"all\", shuffle = True, remove = (\"headers\", \"footers\", \"quotes\"), categories = cats)\n",
    "\n",
    "text, target = data_set.data, data_set.target\n",
    "print (len(text))\n",
    "text = []\n",
    "target = []\n",
    "for i in range(len(data_set.data)):\n",
    "    if len(data_set.data[i]) > 10:\n",
    "        text.append(data_set.data[i])\n",
    "        target.append(data_set.target[i])\n",
    "print (len(text)) \n",
    "\n",
    "vectors = TfidfVectorizer(ngram_range = (1,2), max_df = 0.5, min_df = 5, stop_words = \"english\")\n",
    "features = vectors.fit_transform(text)\n",
    "\n",
    "clfs = {\"SVM\": SGDClassifier(random_state  = 10, alpha = 0.0001), \n",
    "        \"KMEANS\": KMeans(n_clusters = 2, n_jobs = -1, random_state = 10),\n",
    "        \"K-nearest\": KNeighborsClassifier()}\n",
    "\n",
    "for clf in clfs.items():\n",
    "    print (scoring(clf, *train_test_split(features, target, test_size = 0.2, random_state = 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that SVM is really accurate in solving this particular binary classification problem when comparing to K-nearest neighbour and K-mean clustering. \n",
    "\n",
    "Next I am going to attempt to change the vector representation of each text from being a bag of Tf-idf values to a vector derived by averaging the GloVE vectors of its corresponding words. Hopefully, the semantic relationship that GloVE vectors are able to represent will help the data of each label to cluster better in the feature space.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\chatbot\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy: 0.9545454545454546\n",
      "KMEANS accuracy: 0.5714285714285714, homo: 0.005843777657012184, comp: 0.01573009968288095, vm: 0.008521713887694652\n",
      "K-nearest accuracy: 0.922077922077922\n"
     ]
    }
   ],
   "source": [
    "vectors = [nlp(t).vector for t in text]\n",
    "clfs = {\"SVM\": SGDClassifier(random_state  = 10, alpha = 0.0001), \n",
    "        \"KMEANS\": KMeans(n_clusters = 2, n_jobs = -1, random_state = 10),\n",
    "        \"K-nearest\": KNeighborsClassifier()}\n",
    "\n",
    "for clf in clfs.items():\n",
    "    print (scoring(clf, *train_test_split(vectors, target, test_size = 0.2, random_state = 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out that while K-nearest neighbour were able to perform much better, the unsupervised K-mean clustering method is still had quite a large decrease in performance. I suspected that this could be due to the stop word not being removed so the next thing to do is to remove the stop word from being used for the vector computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\chatbot\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy: 0.9512987012987013\n",
      "KMEANS accuracy: 0.8701298701298701, homo: 0.44902065783126033, comp: 0.438862836746917, vm: 0.44388364207043585\n",
      "K-nearest accuracy: 0.9383116883116883\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "sws = set(stopwords.words(\"english\"))\n",
    "\n",
    "text = [\" \".join([word.text for word in nlp(t) if word.text not in sws]) for t in text]\n",
    "vectors = [nlp(t).vector for t in text]\n",
    "\n",
    "clfs = {\"SVM\": SGDClassifier(random_state  = 10, alpha = 0.0001), \n",
    "        \"KMEANS\": KMeans(n_clusters = 2, n_jobs = -1, random_state = 10),\n",
    "        \"K-nearest\": KNeighborsClassifier()}\n",
    "\n",
    "for clf in clfs.items():\n",
    "    print (scoring(clf, *train_test_split(vectors, target, test_size = 0.2, random_state = 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as it turns out, it significantly improved the performances in the unsupervised learning model. \n",
    "Finally, I would to be more specific in what is used to computed the vectors for each body of text. For example, if a human were given a task to classify the text's category, it might be intuitive for a human to pay more attention to the noun in the text, as they are most indicative of what the category is. Similarly, if we were doing sentiment analysis, it might be \n",
    "intuitive to look at the adjective words to decide the sentiment of the text.\n",
    "\n",
    "Therefore, only the GloVE vector of the noun chunks were used to compute the vector representation of the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\chatbot\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy: 0.9285714285714286\n",
      "KMEANS accuracy: 0.9058441558441559, homo: 0.5412801758111346, comp: 0.5380345075451398, vm: 0.5396524615617748\n",
      "K-nearest accuracy: 0.9415584415584416\n"
     ]
    }
   ],
   "source": [
    "text = [\" \".join([chunk.text for chunk in nlp(t).noun_chunks if chunk.text not in sws]) for t in text]\n",
    "vectors = [nlp(t).vector for t in text]\n",
    "\n",
    "clfs = {\"SVM\": SGDClassifier(random_state  = 10, alpha = 0.0001), \n",
    "        \"KMEANS\": KMeans(n_clusters = 2, n_jobs = -1, random_state = 10),\n",
    "        \"K-nearest\": KNeighborsClassifier()}\n",
    "\n",
    "for clf in clfs.items():\n",
    "    print (scoring(clf, *train_test_split(vectors, target, test_size = 0.2, random_state = 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All three models now reaches an above 90% accuracy. Interestingly, both K-nearest neighbour and K-mean clustering had improved significantly from an accuracy of around 65-75% when using a tf-idf vector representation to 90% range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "\n",
    "SVM= [ 0.9253246753246753, 0.9545454545454546, 0.9512987012987013, 0.9285714285714286]\n",
    "KMEANS = [0.762987012987013, 0.5714285714285714, 0.8701298701298701, 0.9058441558441559]\n",
    "Kn = [0.6428571428571429, 0.922077922077922, 0.9383116883116883, 0.9415584415584416]\n",
    "index = np.arange(4)\n",
    "xt = [\"td-idf\", \"GloVE (with stop words)\", \"GloVE (without stop words)\", \"GloVE (noun chunks)\"]\n",
    "bar_width = 0.2\n",
    "\n",
    "rect1 = plt.bar(index, SVM, bar_width, label = \"SVM\")\n",
    "rect2 = plt.bar(index+bar_width, KMEANS, bar_width, label = \"Kmeans\")\n",
    "rect3 = plt.bar(index+2*bar_width, Kn, bar_width, label = \"K-NN\")\n",
    "plt.xticks(index+bar_width, xt, rotation = 45)\n",
    "plt.legend()\n",
    "plt.ylim(0,1.5)\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
